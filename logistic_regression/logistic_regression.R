## Regression with binary outcomes
## ???????????????????????????????????????????????????????????????????????????????????????????????????

## Logistic regression
## ?????????????????????????????????????????????????????????????????????

##   This far we have used the `lm' function to fit our regression models.
##   `lm' is great, but limited???in particular it only fits models for
##   continuous dependent variables. For categorical dependent variables we
##   can use the `glm()' function.

##   For these models we will use a different dataset, drawn from the
##   National Health Interview Survey. From the [CDC website]:

##         The National Health Interview Survey (NHIS) has monitored
##         the health of the nation since 1957. NHIS data on a broad
##         range of health topics are collected through personal
##         household interviews. For over 50 years, the U.S. Census
##         Bureau has been the data collection agent for the National
##         Health Interview Survey. Survey results have been
##         instrumental in providing data to track health status,
##         health care access, and progress toward achieving national
##         health objectives.

##   Load the National Health Interview Survey data:

root <- "/Users/bmetcalf2/WorkSpaceR/Log_regress/logistic_regression"
NH11 <- readRDS(paste(root,"/dataSets/NatHealth2011.rds",sep=''))
labs <- attributes(NH11)$labels

##   [CDC website] http://www.cdc.gov/nchs/nhis.htm

## Logistic regression example
## ?????????????????????????????????????????????????????????????????????????????????????????????

##   Let's predict the probability of being diagnosed with hypertension
##   based on age, sex, sleep, and bmi

str(NH11$hypev) # check stucture of hypev
levels(NH11$hypev) # check levels of hypev
# collapse all missing values to NA
NH11$hypev <- factor(NH11$hypev, levels=c("2 No", "1 Yes"))
# run our regression model
hyp.out <- glm(hypev~age_p+sex+sleep+bmi,
               data=NH11, family="binomial")
coef(summary(hyp.out))

## Logistic regression coefficients
## ????????????????????????????????????????????????????????????????????????????????????????????????????????????

##   Generalized linear models use link functions, so raw coefficients are
##   difficult to interpret. For example, the age coefficient of .06 in the
##   previous model tells us that for every one unit increase in age, the
##   log odds of hypertension diagnosis increases by 0.06. Since most of us
##   are not used to thinking in log odds this is not too helpful!

##   One solution is to transform the coefficients to make them easier to
##   interpret

hyp.out.tab <- coef(summary(hyp.out))
hyp.out.tab[, "Estimate"] <- exp(coef(hyp.out))
hyp.out.tab

## Generating predicted values
## ?????????????????????????????????????????????????????????????????????????????????????????????

##   In addition to transforming the log-odds produced by `glm' to odds, we
##   can use the `predict()' function to make direct statements about the
##   predictors in our model. For example, we can ask "How much more likely
##   is a 63 year old female to have hypertension compared to a 33 year old
##   female?".

# Create a dataset with predictors set at desired levels
predDat <- with(NH11,
                expand.grid(age_p = c(33, 63),
                            sex = "2 Female",
                            bmi = mean(bmi, na.rm = TRUE),
                            sleep = mean(sleep, na.rm = TRUE)))
# predict hypertension at those levels
cbind(predDat, predict(hyp.out, type = "response",
                       se.fit = TRUE, interval="confidence",
                       newdata = predDat))

##   This tells us that a 33 year old female has a 13% probability of
##   having been diagnosed with hypertension, while and 63 year old female
##   has a 48% probability of having been diagnosed.

## Packages for  computing and graphing predicted values
## ???????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????????

##   Instead of doing all this ourselves, we can use the effects package to
##   compute quantities of interest for us (cf. the Zelig package).

library(effects)
plot(allEffects(hyp.out))

## Exercise: logistic regression
## ?????????????????????????????????????????????????????????????????????????????????????????????????????????

##   Use the NH11 data set that we loaded earlier.

##   1. Use glm to conduct a logistic regression to predict ever worked
##      (everwrk) using age (age_p) and marital status (r_maritl).
##   2. Predict the probability of working for each level of marital
##      status.

##   Note that the data is not perfectly clean and ready to be modeled. You
##   will need to clean up at least some of the variables before fitting
##   the model.

# take only the important columns
short_nh11 <- NH11[,c('hypev','everwrk','age_p','r_maritl')]
# take out NA cases
short_nh11 <- subset(short_nh11,!is.na(hypev)) 
short_nh11 <- subset(short_nh11,!is.na(everwrk))

short_nh11 <- subset(short_nh11,everwrk == "1 Yes" | everwrk == "2 No")

subset(short_nh11,is.na(hypev))
subset(short_nh11,is.na(everwrk))
subset(short_nh11,is.na(age_p))
subset(short_nh11,is.na(r_maritl))

library("dplyr")
levels(short_nh11$everwrk)

levels(short_nh11$r_maritl)
summary(short_nh11$r_maritl)

library(ggplot2)
ggplot(short_nh11,aes(x=r_maritl) ) + 
  geom_bar(stat="count")

# This marital variable is categorical and has no logical ordering to it.
# If it is left as a single variable there might be problems with any classifier 
# or regression method that relies on a linear combination of variables.
#  There for I will break this variable up into 5 binary variable.

lev <- levels(short_nh11$r_maritl)
lev
short_nh11 <-  short_nh11 %>% mutate(Divorced_Seporated = ((r_maritl == lev[6]) | (r_maritl == lev[7] | r_maritl == lev[3]) )*1 ) %>% 
  mutate(Never_married = ((r_maritl == lev[1]) | (r_maritl == lev[8]) )*1 ) %>% 
  mutate(Widowed = (r_maritl == lev[5] )*1 ) %>% 
  mutate(Married = ( (r_maritl == lev[2]) | (r_maritl == lev[4]) )*1 ) %>% 
  mutate(Living_unmarried = (r_maritl == lev[9] )*1 )

# unknown marital status will just have no entry for marital status
# married but living apart goes into Divorced_Seporated
# "Married - spouse in household unknown" goes into Married

levs <- levels(short_nh11$hypev)
# I put in this just to get it in the normal ordering of false less than true
short_nh11 <- short_nh11 %>% mutate(hypev_logic = (hypev == levs[2]))

# run our regression model
hyp.out <- glm(hypev_logic ~ age_p+everwrk+Divorced_Seporated+Never_married+Widowed+Married +
                 Living_unmarried,data=short_nh11, family="binomial")
coef(summary(hyp.out))

hyp.out.tab <- coef(summary(hyp.out))
hyp.out.tab[, "Estimate"] <- exp(coef(hyp.out))
hyp.out.tab

plot(allEffects(hyp.out))

# construct a ROC curve
assert_that( all( !is.na(short_nh11) ) )
respons <-  predict(hyp.out,data=short_nh11,type='response')
assert_that(nrow(short_nh11) == length(respons))

library(ROCR)
pred <- prediction(respons,short_nh11$hypev_logic)
perf <- performance(pred,"tpr","fpr")
plot(perf)

# Calculate the area under the ROC curve
perf <- performance(pred,"auc")
perf@y.values[1]

# Not that great a classifier